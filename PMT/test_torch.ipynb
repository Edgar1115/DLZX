{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcf2b08-542c-4946-8408-15215af79dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922e4f94-d4e8-4c76-82c1-a0bb5b6bfc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1111, 1112, 1113, 1114],\n",
      "          [1121, 1122, 1123, 1124],\n",
      "          [1131, 1132, 1133, 1134]],\n",
      "\n",
      "         [[1211, 1212, 1213, 1214],\n",
      "          [1221, 1222, 1223, 1224],\n",
      "          [1231, 1232, 1233, 1234]],\n",
      "\n",
      "         [[1311, 1312, 1313, 1314],\n",
      "          [1321, 1322, 1323, 1324],\n",
      "          [1331, 1332, 1333, 1334]]],\n",
      "\n",
      "\n",
      "        [[[2111, 2112, 2113, 2114],\n",
      "          [2121, 2122, 2123, 2124],\n",
      "          [2131, 2132, 2133, 2134]],\n",
      "\n",
      "         [[2211, 2212, 2213, 2214],\n",
      "          [2221, 2222, 2223, 2224],\n",
      "          [2231, 2232, 2233, 2234]],\n",
      "\n",
      "         [[2311, 2312, 2313, 2314],\n",
      "          [2321, 2322, 2323, 2324],\n",
      "          [2331, 2332, 2333, 2334]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[[1111, 1112, 1113, 1114],\n",
    "                    [1121, 1122, 1123, 1124],\n",
    "                    [1131, 1132, 1133, 1134]],\n",
    "\n",
    "                   [[1211, 1212, 1213, 1214],\n",
    "                    [1221, 1222, 1223, 1224],\n",
    "                    [1231, 1232, 1233, 1234]],\n",
    "\n",
    "                   [[1311, 1312, 1313, 1314],\n",
    "                    [1321, 1322, 1323, 1324],\n",
    "                    [1331, 1332, 1333, 1334]]],\n",
    "\n",
    "                  [[[2111, 2112, 2113, 2114],\n",
    "                    [2121, 2122, 2123, 2124],\n",
    "                    [2131, 2132, 2133, 2134]],\n",
    "\n",
    "                   [[2211, 2212, 2213, 2214],\n",
    "                    [2221, 2222, 2223, 2224],\n",
    "                    [2231, 2232, 2233, 2234]],\n",
    "\n",
    "                   [[2311, 2312, 2313, 2314],\n",
    "                    [2321, 2322, 2323, 2324],\n",
    "                    [2331, 2332, 2333, 2334]]]], dtype=torch.int32)\n",
    "\n",
    "\n",
    "print(x)\n",
    "\n",
    "xin = x.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420a794-bf10-4d09-bad6-ff5d289342bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "x[B,C,H,W] -> x1[B,W,C,H]\n",
    "\n",
    "\n",
    "batch不变，每张图片变为高度为C，宽度为H，通道数为W\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb86b650-0b8e-4d6b-ab06-abaaa6042208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1111, 1121, 1131],\n",
      "          [1211, 1221, 1231],\n",
      "          [1311, 1321, 1331]],\n",
      "\n",
      "         [[1112, 1122, 1132],\n",
      "          [1212, 1222, 1232],\n",
      "          [1312, 1322, 1332]],\n",
      "\n",
      "         [[1113, 1123, 1133],\n",
      "          [1213, 1223, 1233],\n",
      "          [1313, 1323, 1333]],\n",
      "\n",
      "         [[1114, 1124, 1134],\n",
      "          [1214, 1224, 1234],\n",
      "          [1314, 1324, 1334]]],\n",
      "\n",
      "\n",
      "        [[[2111, 2121, 2131],\n",
      "          [2211, 2221, 2231],\n",
      "          [2311, 2321, 2331]],\n",
      "\n",
      "         [[2112, 2122, 2132],\n",
      "          [2212, 2222, 2232],\n",
      "          [2312, 2322, 2332]],\n",
      "\n",
      "         [[2113, 2123, 2133],\n",
      "          [2213, 2223, 2233],\n",
      "          [2313, 2323, 2333]],\n",
      "\n",
      "         [[2114, 2124, 2134],\n",
      "          [2214, 2224, 2234],\n",
      "          [2314, 2324, 2334]]]], dtype=torch.int32)\n",
      "torch.Size([2, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x1 = x.permute(0, 3, 1, 2)\n",
    "\n",
    "print(x1)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee294310-86af-4613-a97b-c43b9414e9ad",
   "metadata": {},
   "source": [
    "---\n",
    "x[B,C,H,W] -> x1[B,H,C,W]\n",
    "\n",
    "batch与图片宽度不变，每张图片高度变为C，通道数变为H\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12c1f34-4d11-4558-adaf-81147d1ea8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1111, 1112, 1113, 1114],\n",
      "          [1211, 1212, 1213, 1214],\n",
      "          [1311, 1312, 1313, 1314]],\n",
      "\n",
      "         [[1121, 1122, 1123, 1124],\n",
      "          [1221, 1222, 1223, 1224],\n",
      "          [1321, 1322, 1323, 1324]],\n",
      "\n",
      "         [[1131, 1132, 1133, 1134],\n",
      "          [1231, 1232, 1233, 1234],\n",
      "          [1331, 1332, 1333, 1334]]],\n",
      "\n",
      "\n",
      "        [[[2111, 2112, 2113, 2114],\n",
      "          [2211, 2212, 2213, 2214],\n",
      "          [2311, 2312, 2313, 2314]],\n",
      "\n",
      "         [[2121, 2122, 2123, 2124],\n",
      "          [2221, 2222, 2223, 2224],\n",
      "          [2321, 2322, 2323, 2324]],\n",
      "\n",
      "         [[2131, 2132, 2133, 2134],\n",
      "          [2231, 2232, 2233, 2234],\n",
      "          [2331, 2332, 2333, 2334]]]], dtype=torch.int32)\n",
      "torch.Size([2, 3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x2 = x.permute(0, 2, 1, 3)\n",
    "\n",
    "print(x2)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff2a9c-404e-4ba3-a381-3d56d2fddff0",
   "metadata": {},
   "source": [
    "---\n",
    "x1[B,C',H',W']->x1'[B*C',H',W']\n",
    "\n",
    "batch改变，从二维矩阵变为一维向量\n",
    "\n",
    "改变前：\n",
    "B个batch，每张图片高为H',宽为W',通道为C'\n",
    "\n",
    "改变后：\n",
    "B*C'个batch，每个向量长为W',通道数为H'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7dbf212-b5c7-4394-bd31-0f1fbe0d0ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1111, 1121, 1131],\n",
      "         [1211, 1221, 1231],\n",
      "         [1311, 1321, 1331]],\n",
      "\n",
      "        [[1112, 1122, 1132],\n",
      "         [1212, 1222, 1232],\n",
      "         [1312, 1322, 1332]],\n",
      "\n",
      "        [[1113, 1123, 1133],\n",
      "         [1213, 1223, 1233],\n",
      "         [1313, 1323, 1333]],\n",
      "\n",
      "        [[1114, 1124, 1134],\n",
      "         [1214, 1224, 1234],\n",
      "         [1314, 1324, 1334]],\n",
      "\n",
      "        [[2111, 2121, 2131],\n",
      "         [2211, 2221, 2231],\n",
      "         [2311, 2321, 2331]],\n",
      "\n",
      "        [[2112, 2122, 2132],\n",
      "         [2212, 2222, 2232],\n",
      "         [2312, 2322, 2332]],\n",
      "\n",
      "        [[2113, 2123, 2133],\n",
      "         [2213, 2223, 2233],\n",
      "         [2313, 2323, 2333]],\n",
      "\n",
      "        [[2114, 2124, 2134],\n",
      "         [2214, 2224, 2234],\n",
      "         [2314, 2324, 2334]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "N1, W1, C1, H1 = x1.shape\n",
    "x1 = x1.contiguous().view(N1 * W1, C1, H1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa4c91-4db2-49b1-8bb1-a72990e35056",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "同x1的变化\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f35928-6f1d-420e-99dc-d43410801d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1111, 1112, 1113, 1114],\n",
      "         [1211, 1212, 1213, 1214],\n",
      "         [1311, 1312, 1313, 1314]],\n",
      "\n",
      "        [[1121, 1122, 1123, 1124],\n",
      "         [1221, 1222, 1223, 1224],\n",
      "         [1321, 1322, 1323, 1324]],\n",
      "\n",
      "        [[1131, 1132, 1133, 1134],\n",
      "         [1231, 1232, 1233, 1234],\n",
      "         [1331, 1332, 1333, 1334]],\n",
      "\n",
      "        [[2111, 2112, 2113, 2114],\n",
      "         [2211, 2212, 2213, 2214],\n",
      "         [2311, 2312, 2313, 2314]],\n",
      "\n",
      "        [[2121, 2122, 2123, 2124],\n",
      "         [2221, 2222, 2223, 2224],\n",
      "         [2321, 2322, 2323, 2324]],\n",
      "\n",
      "        [[2131, 2132, 2133, 2134],\n",
      "         [2231, 2232, 2233, 2234],\n",
      "         [2331, 2332, 2333, 2334]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "N2, W2, C2, H2 = x2.shape\n",
    "x2 = x2.contiguous().view(N2 * W2, C2, H2)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556b00da-f6ba-42f3-87d6-511256f4acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: torch.Size([8, 3, 3])\n",
      "x2: torch.Size([6, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"x1:\",x1.shape)\n",
    "print(\"x2:\",x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2310ac-3f63-4825-b0c9-499696616643",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690ced22-e230-4c59-b07b-0f22af015988",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_reshape = qkv.reshape(\n",
    "    8,\n",
    "    1,\n",
    "    3,\n",
    "    3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d983f46-46b2-4dfa-bf9f-5aa91b0d971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 3, 3])\n",
      "tensor([[[[1111, 1121, 1131],\n",
      "          [1211, 1221, 1231],\n",
      "          [1311, 1321, 1331]]],\n",
      "\n",
      "\n",
      "        [[[1112, 1122, 1132],\n",
      "          [1212, 1222, 1232],\n",
      "          [1312, 1322, 1332]]],\n",
      "\n",
      "\n",
      "        [[[1113, 1123, 1133],\n",
      "          [1213, 1223, 1233],\n",
      "          [1313, 1323, 1333]]],\n",
      "\n",
      "\n",
      "        [[[1114, 1124, 1134],\n",
      "          [1214, 1224, 1234],\n",
      "          [1314, 1324, 1334]]],\n",
      "\n",
      "\n",
      "        [[[2111, 2121, 2131],\n",
      "          [2211, 2221, 2231],\n",
      "          [2311, 2321, 2331]]],\n",
      "\n",
      "\n",
      "        [[[2112, 2122, 2132],\n",
      "          [2212, 2222, 2232],\n",
      "          [2312, 2322, 2332]]],\n",
      "\n",
      "\n",
      "        [[[2113, 2123, 2133],\n",
      "          [2213, 2223, 2233],\n",
      "          [2313, 2323, 2333]]],\n",
      "\n",
      "\n",
      "        [[[2114, 2124, 2134],\n",
      "          [2214, 2224, 2234],\n",
      "          [2314, 2324, 2334]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(qkv_reshape.shape)\n",
    "print(qkv_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa9cea1-efbd-4b91-91c2-7351d79e84b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1111, 1121, 1131]]],\n",
      "\n",
      "\n",
      "        [[[1112, 1122, 1132]]],\n",
      "\n",
      "\n",
      "        [[[1113, 1123, 1133]]],\n",
      "\n",
      "\n",
      "        [[[1114, 1124, 1134]]],\n",
      "\n",
      "\n",
      "        [[[2111, 2121, 2131]]],\n",
      "\n",
      "\n",
      "        [[[2112, 2122, 2132]]],\n",
      "\n",
      "\n",
      "        [[[2113, 2123, 2133]]],\n",
      "\n",
      "\n",
      "        [[[2114, 2124, 2134]]]], dtype=torch.int32)\n",
      "tensor([[[[1211, 1221, 1231]]],\n",
      "\n",
      "\n",
      "        [[[1212, 1222, 1232]]],\n",
      "\n",
      "\n",
      "        [[[1213, 1223, 1233]]],\n",
      "\n",
      "\n",
      "        [[[1214, 1224, 1234]]],\n",
      "\n",
      "\n",
      "        [[[2211, 2221, 2231]]],\n",
      "\n",
      "\n",
      "        [[[2212, 2222, 2232]]],\n",
      "\n",
      "\n",
      "        [[[2213, 2223, 2233]]],\n",
      "\n",
      "\n",
      "        [[[2214, 2224, 2234]]]], dtype=torch.int32)\n",
      "tensor([[[[1311, 1321, 1331]]],\n",
      "\n",
      "\n",
      "        [[[1312, 1322, 1332]]],\n",
      "\n",
      "\n",
      "        [[[1313, 1323, 1333]]],\n",
      "\n",
      "\n",
      "        [[[1314, 1324, 1334]]],\n",
      "\n",
      "\n",
      "        [[[2311, 2321, 2331]]],\n",
      "\n",
      "\n",
      "        [[[2312, 2322, 2332]]],\n",
      "\n",
      "\n",
      "        [[[2313, 2323, 2333]]],\n",
      "\n",
      "\n",
      "        [[[2314, 2324, 2334]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "split_sizes = [\n",
    "    1,   # q\n",
    "    1,   # k\n",
    "    1         # v\n",
    "]\n",
    "\n",
    "q, k, v = torch.split(\n",
    "    qkv_reshape,\n",
    "    split_sizes,\n",
    "    dim=2\n",
    ")\n",
    "print(q)\n",
    "print(k)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32cbd6-56b7-432a-8d83-b4808a099b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
