{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd62887-c7fc-4022-81cb-1d2d6cc7f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.segmentation import ImageSegmentationDataset\n",
    "from transforms.base import Compose, ToTensor\n",
    "from transforms.vision_basic import Resize, RandomHorizontalFlip,RandomVerticalFlip,Normalize\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcc0dc7-d0d2-4abc-9767-f5f062d6be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num images: 20\n",
      "num masks : 20\n",
      "first 3 images: ['../data/DRIVE/training/images/21_training.tif', '../data/DRIVE/training/images/22_training.tif', '../data/DRIVE/training/images/23_training.tif']\n",
      "first 3 masks : ['../data/DRIVE/training/1st_manual/21_manual1.gif', '../data/DRIVE/training/1st_manual/22_manual1.gif', '../data/DRIVE/training/1st_manual/23_manual1.gif']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "img_dir  = Path(\"../data/DRIVE/training/images\")\n",
    "mask_dir = Path(\"../data/DRIVE/training/1st_manual\")\n",
    "\n",
    "# 1. 把目录里所有 .tif / .gif 文件取出来，并排序，保持一一对应\n",
    "image_paths = sorted(str(p) for p in img_dir.glob(\"*.tif\"))\n",
    "mask_paths  = sorted(str(p) for p in mask_dir.glob(\"*.gif\"))\n",
    "\n",
    "print(\"num images:\", len(image_paths))\n",
    "print(\"num masks :\", len(mask_paths))\n",
    "print(\"first 3 images:\", image_paths[:3])\n",
    "print(\"first 3 masks :\", mask_paths[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b921dd58-7ccf-422e-9142-c3da2b47f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(\n",
    "        mean = [0.485,0.456,0.406],\n",
    "        std = [0.229,0.224,0.225],\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918c4b78-879c-4d9c-91d1-49ebe76d9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 构建 Dataset 和 DataLoader\n",
    "ds = ImageSegmentationDataset(\n",
    "    image_paths=image_paths,\n",
    "    mask_paths=mask_paths,\n",
    "    transform=seg_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9b7405-0515-4b7b-96d7-8dfe256a6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_loader = DataLoader(ds,batch_size = 1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f4eea7-b0f0-4b2b-bd26-c4892afcef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for batch in seg_loader:\n",
    "    print(batch[\"image\"].shape)  # 预期: [1, 3, 224, 224]\n",
    "    print(batch[\"mask\"].shape)   # 预期: [1, 224, 224] 或 [224, 224]，我们下一步来调整\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "509f3a6c-8211-4a44-b1e5-88ed5682f278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: torch.float32 torch.Size([1, 3, 224, 224])\n",
      "mask: torch.int64 torch.Size([1, 224, 224])\n",
      "mask unique values: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch in seg_loader:\n",
    "    print(\"image:\", batch[\"image\"].dtype, batch[\"image\"].shape)\n",
    "    print(\"mask:\", batch[\"mask\"].dtype, batch[\"mask\"].shape)\n",
    "    print(\"mask unique values:\", batch[\"mask\"].unique())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f19f3f0-4a5e-483c-9895-7e56cdf9ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ds) = 20\n",
      "torch.Size([1, 3, 224, 224]) torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(\"len(ds) =\", len(ds))\n",
    "for batch in seg_loader:\n",
    "    print(batch[\"image\"].shape, batch[\"mask\"].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb55b4c-b92b-4da2-b33b-cb84968ad591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
