{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c2fca4-d7e5-4e04-a7ad-615dd7a2645b",
   "metadata": {},
   "source": [
    "# 使用 data_package 做图像分割示例（DRIVE）\n",
    "\n",
    "本 Notebook 演示如何使用 `ImageSegmentationDataset` 和 `transforms` 来完成：\n",
    "\n",
    "1. 构建图像与 mask 路径；\n",
    "2. train / val / test 划分；\n",
    "3. 定义适合买分割的 transforms（包括随机翻转）；\n",
    "4. 构建 DataLoader，并检查 image / mask 的 dtype 和 shape。\n",
    "\n",
    "模型部分这里只写一个骨架，你可以接上自己的 UNet / DeepLabV3。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe2f7a0-3ccf-4b18-a71e-e105af57daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import ImageSegmentationDataset\n",
    "from transforms import (\n",
    "    Compose, Resize, RandomHorizontalFlip, RandomVerticalFlip,RandomRotate90,\n",
    "    ToTensor, Normalize,\n",
    ")\n",
    "from utils import train_val_test_split,compute_channel_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad927105-477d-4780-91b3-87311d7dd773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num images: 20\n",
      "num masks : 20\n",
      "first image: ../data/DRIVE/training/images/21_training.tif\n",
      "first mask : ../data/DRIVE/training/1st_manual/21_manual1.gif\n"
     ]
    }
   ],
   "source": [
    "img_dir = Path(\"../data/DRIVE/training/images\")\n",
    "mask_dir = Path(\"../data/DRIVE/training/1st_manual\")\n",
    "\n",
    "image_paths = sorted(str(p) for p in img_dir.glob(\"*.tif\"))\n",
    "mask_paths = sorted(str(p) for p in mask_dir.glob(\"*.gif\"))\n",
    "\n",
    "print(\"num images:\", len(image_paths))\n",
    "print(\"num masks :\", len(mask_paths))\n",
    "print(\"first image:\", image_paths[0])\n",
    "print(\"first mask :\", mask_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbfc643-eebd-4870-8720-7b18ea90a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / val / test: 14 3 3\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_imgs, val_imgs, test_imgs,\n",
    "    train_masks, val_masks, test_masks\n",
    ") = train_val_test_split(\n",
    "    image_paths, mask_paths,\n",
    "    train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,\n",
    "    shuffle=True, seed=42,\n",
    ")\n",
    "\n",
    "print(\"train / val / test:\", len(train_imgs), len(val_imgs), len(test_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c2a4ef-2674-4fd1-b912-30bf0bc1a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4877, 0.2693, 0.1641])\n",
      "std : tensor([0.3408, 0.1859, 0.1067])\n"
     ]
    }
   ],
   "source": [
    "# 1. 建一个“没有 Normalize 的”临时 Dataset\n",
    "tmp_tf = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(mask_mode=\"none\"),  # 重要：还不能 Normalize\n",
    "])\n",
    "\n",
    "tmp_train_ds = ImageSegmentationDataset(\n",
    "    image_paths=train_imgs,\n",
    "    mask_paths=train_masks,\n",
    "    transform=tmp_tf,\n",
    ")\n",
    "\n",
    "# 2. 估计 mean / std（可以只用前几百个 batch）\n",
    "mean, std = compute_channel_mean_std(tmp_train_ds, batch_size=16, max_batches=50)\n",
    "print(\"mean:\", mean)\n",
    "print(\"std :\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeeeeec3-4b29-4818-91a3-c8d42077e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRIVE 是二类（血管 / 非血管），mask 像素一般是 0 和 255\n",
    "# 所以这里用 mask_mode=\"binary\" 即可\n",
    "train_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    RandomRotate90(p=0.5),\n",
    "    ToTensor(mask_mode=\"binary\"),\n",
    "    Normalize(\n",
    "        mean=mean.tolist(),\n",
    "        std=std.tolist(),\n",
    "    ),\n",
    "])\n",
    "\n",
    "eval_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(mask_mode=\"binary\"),\n",
    "    Normalize(\n",
    "        mean=mean.tolist(),\n",
    "        std=std.tolist(),\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a583c699-ea38-49da-bd23-1fe3e0afa0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: torch.float32 torch.Size([2, 3, 224, 224])\n",
      "mask : torch.int64 torch.Size([2, 224, 224])\n",
      "mask unique: tensor([0, 1])\n",
      "meta: {'image_path': ['../data/DRIVE/training/images/32_training.tif', '../data/DRIVE/training/images/37_training.tif'], 'mask_path': ['../data/DRIVE/training/1st_manual/32_manual1.gif', '../data/DRIVE/training/1st_manual/37_manual1.gif'], 'index': tensor([12, 10])}\n"
     ]
    }
   ],
   "source": [
    "train_ds = ImageSegmentationDataset(\n",
    "    image_paths=train_imgs,\n",
    "    mask_paths=train_masks,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "val_ds = ImageSegmentationDataset(\n",
    "    image_paths=val_imgs,\n",
    "    mask_paths=val_masks,\n",
    "    transform=eval_transform,\n",
    ")\n",
    "\n",
    "test_ds = ImageSegmentationDataset(\n",
    "    image_paths=test_imgs,\n",
    "    mask_paths=test_masks,\n",
    "    transform=eval_transform,\n",
    ")\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size, shuffle=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(\"image:\", batch[\"image\"].dtype, batch[\"image\"].shape)  # [B, 3, 224, 224]\n",
    "    print(\"mask :\", batch[\"mask\"].dtype, batch[\"mask\"].shape)    # [B, 224, 224]\n",
    "    print(\"mask unique:\", batch[\"mask\"].unique())\n",
    "    print(\"meta:\", batch[\"meta\"])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed81c56a-bb8a-42ce-a125-c43367d8cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DummySegModel(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        # 非常简单的 U-Net 风格占位结构，你可换成真正的实现\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(16, num_classes, kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x  # [B, num_classes, H, W]，配合 CrossEntropyLoss\n",
    "\n",
    "\n",
    "num_classes = 2  # DRIVE 是二类分割；多类分割时改成对应类别数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DummySegModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ace57c8-f267-48b4-afc8-3599351c2a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.5875\n",
      "Epoch 2: train_loss=0.5530\n"
     ]
    }
   ],
   "source": [
    "def train_seg_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_pixels = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        imgs = batch[\"image\"].to(device)              # [B, 3, H, W]\n",
    "        masks = batch[\"mask\"].to(device)              # [B, H, W]，long，0~C-1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)                          # [B, C, H, W]\n",
    "        loss = criterion(logits, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        total_pixels += imgs.size(0)\n",
    "\n",
    "    return total_loss / total_pixels\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "    train_loss = train_seg_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff5e3-a251-4d30-9f0b-479ca99fd885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
